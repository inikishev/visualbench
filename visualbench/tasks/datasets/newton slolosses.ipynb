{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal dice\n",
      "0, loss = tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "1, loss = tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "2, loss = tensor(1.3433, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "3, loss = tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "4, loss = tensor(1.3431, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "5, loss = tensor(1.3431, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "6, loss = tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "7, loss = tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "8, loss = tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "9, loss = tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "10, loss = tensor(1.3426, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "11, loss = tensor(1.3425, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "12, loss = tensor(1.3425, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "13, loss = tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "14, loss = tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "15, loss = tensor(1.3422, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "16, loss = tensor(1.3421, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "17, loss = tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "18, loss = tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "19, loss = tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "20, loss = tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "21, loss = tensor(1.3417, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "22, loss = tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "23, loss = tensor(1.3415, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "24, loss = tensor(1.3414, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "25, loss = tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "26, loss = tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "27, loss = tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "28, loss = tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "29, loss = tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "30, loss = tensor(1.3409, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "31, loss = tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "32, loss = tensor(1.3407, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "33, loss = tensor(1.3407, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "34, loss = tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "35, loss = tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "36, loss = tensor(1.3404, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37, loss = tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38, loss = tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "39, loss = tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40, loss = tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41, loss = tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42, loss = tensor(1.3399, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43, loss = tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44, loss = tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45, loss = tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46, loss = tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47, loss = tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48, loss = tensor(1.3394, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49, loss = tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50, loss = tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51, loss = tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52, loss = tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53, loss = tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54, loss = tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55, loss = tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56, loss = tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57, loss = tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "58, loss = tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "59, loss = tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "60, loss = tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "61, loss = tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "62, loss = tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "63, loss = tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "64, loss = tensor(1.3380, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "65, loss = tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "66, loss = tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "67, loss = tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "68, loss = tensor(1.3377, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "69, loss = tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "70, loss = tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "71, loss = tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "72, loss = tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "73, loss = tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "74, loss = tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "75, loss = tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "76, loss = tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "77, loss = tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "78, loss = tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "79, loss = tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "80, loss = tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "81, loss = tensor(1.3366, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "82, loss = tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "83, loss = tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "84, loss = tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "85, loss = tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "86, loss = tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "87, loss = tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "88, loss = tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "89, loss = tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "90, loss = tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "91, loss = tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "92, loss = tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "93, loss = tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "94, loss = tensor(1.3355, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "95, loss = tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "96, loss = tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "97, loss = tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "98, loss = tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "99, loss = tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>), mse = tensor(1.5286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "newton dice\n",
      "0, loss = tensor(1.3435, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "1, loss = tensor(1.3350, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.5285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "2, loss = tensor(1.3268, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.4967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "3, loss = tensor(1.3187, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.4658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "4, loss = tensor(1.3107, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.4358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "5, loss = tensor(1.3030, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.4065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "6, loss = tensor(1.2954, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.3781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "7, loss = tensor(1.2880, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "8, loss = tensor(1.2808, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.3235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "9, loss = tensor(1.2738, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "10, loss = tensor(1.2669, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "11, loss = tensor(1.2602, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.2473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "12, loss = tensor(1.2536, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.2233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "13, loss = tensor(1.2472, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "14, loss = tensor(1.2409, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.1775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "15, loss = tensor(1.2348, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "16, loss = tensor(1.2289, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "17, loss = tensor(1.2231, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.1136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "18, loss = tensor(1.2175, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.0936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "19, loss = tensor(1.2120, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.0741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "20, loss = tensor(1.2066, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "21, loss = tensor(1.2014, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.0370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "22, loss = tensor(1.1963, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.0193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "23, loss = tensor(1.1913, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(1.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "24, loss = tensor(1.1865, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.9855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "25, loss = tensor(1.1818, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "26, loss = tensor(1.1772, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "27, loss = tensor(1.1727, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.9387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "28, loss = tensor(1.1684, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "29, loss = tensor(1.1642, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "30, loss = tensor(1.1601, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "31, loss = tensor(1.1560, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "32, loss = tensor(1.1522, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "33, loss = tensor(1.1484, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "34, loss = tensor(1.1447, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "35, loss = tensor(1.1411, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "36, loss = tensor(1.1376, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37, loss = tensor(1.1342, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38, loss = tensor(1.1309, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "39, loss = tensor(1.1277, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40, loss = tensor(1.1245, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41, loss = tensor(1.1215, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42, loss = tensor(1.1185, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43, loss = tensor(1.1156, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44, loss = tensor(1.1128, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45, loss = tensor(1.1101, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46, loss = tensor(1.1074, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47, loss = tensor(1.1048, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48, loss = tensor(1.1023, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49, loss = tensor(1.0998, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50, loss = tensor(1.0974, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51, loss = tensor(1.0951, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52, loss = tensor(1.0928, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53, loss = tensor(1.0906, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54, loss = tensor(1.0885, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55, loss = tensor(1.0864, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56, loss = tensor(1.0843, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57, loss = tensor(1.0823, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "58, loss = tensor(1.0804, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "59, loss = tensor(1.0785, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "60, loss = tensor(1.0767, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "61, loss = tensor(1.0749, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "62, loss = tensor(1.0731, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "63, loss = tensor(1.0714, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "64, loss = tensor(1.0698, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "65, loss = tensor(1.0681, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "66, loss = tensor(1.0666, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "67, loss = tensor(1.0650, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "68, loss = tensor(1.0635, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "69, loss = tensor(1.0620, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "70, loss = tensor(1.0606, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "71, loss = tensor(1.0592, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "72, loss = tensor(1.0578, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "73, loss = tensor(1.0565, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "74, loss = tensor(1.0552, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "75, loss = tensor(1.0539, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "76, loss = tensor(1.0526, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "77, loss = tensor(1.0514, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "78, loss = tensor(1.0502, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "79, loss = tensor(1.0491, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "80, loss = tensor(1.0479, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "81, loss = tensor(1.0468, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "82, loss = tensor(1.0457, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "83, loss = tensor(1.0447, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "84, loss = tensor(1.0436, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "85, loss = tensor(1.0426, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "86, loss = tensor(1.0416, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "87, loss = tensor(1.0406, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "88, loss = tensor(1.0397, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "89, loss = tensor(1.0388, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "90, loss = tensor(1.0378, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "91, loss = tensor(1.0369, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "92, loss = tensor(1.0361, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "93, loss = tensor(1.0352, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "94, loss = tensor(1.0344, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "95, loss = tensor(1.0335, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "96, loss = tensor(1.0327, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "97, loss = tensor(1.0319, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "98, loss = tensor(1.0312, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "99, loss = tensor(1.0304, device='cuda:0', grad_fn=<BatchedNewtonLossBackward>), mse = tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Iterable, Sequence\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def jacobian(input: Sequence[torch.Tensor], wrt: Sequence[torch.Tensor], create_graph=False):\n",
    "    flat_input = torch.cat([i.reshape(-1) for i in input])\n",
    "    return torch.autograd.grad(\n",
    "        flat_input,\n",
    "        wrt,\n",
    "        torch.eye(len(flat_input), device=input[0].device, dtype=input[0].dtype),\n",
    "        retain_graph=True,\n",
    "        create_graph=create_graph,\n",
    "        allow_unused=True,\n",
    "        is_grads_batched=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def make_newton_loss(loss_fn, tik_l: float = 1e-2):\n",
    "\n",
    "    class NewtonLoss(torch.autograd.Function):\n",
    "\n",
    "        @staticmethod\n",
    "        def forward(ctx, preds: torch.Tensor, targets: torch.Tensor):\n",
    "            with torch.enable_grad():\n",
    "                # necessary to flatten preds FIRST so they are part of the graph\n",
    "                preds_flat = preds.ravel()\n",
    "                value = loss_fn(preds_flat.view_as(preds), targets)\n",
    "\n",
    "                # caluclate gradient and hessian\n",
    "                g = torch.autograd.grad(value, preds_flat, create_graph=True)[0]\n",
    "                H: torch.Tensor = jacobian([g], [preds_flat])[0]\n",
    "\n",
    "            # apply regularization\n",
    "            if tik_l != 0:\n",
    "                H.add_(torch.eye(H.size(0), device=H.device, dtype=H.dtype).mul_(tik_l))\n",
    "\n",
    "            # newton step\n",
    "            newton_step, success = torch.linalg.solve_ex(H, g)\n",
    "            ctx.save_for_backward(newton_step.view_as(preds))\n",
    "\n",
    "            return value\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, *grad_outputs):\n",
    "            newton_step = ctx.saved_tensors[0] # inputs to loss\n",
    "            return newton_step, None\n",
    "\n",
    "    return NewtonLoss.apply\n",
    "\n",
    "\n",
    "def make_batched_newton_loss(loss_fn, tik_l: float = 1e-2):\n",
    "\n",
    "    class BatchedNewtonLoss(torch.autograd.Function):\n",
    "\n",
    "        @staticmethod\n",
    "        def forward(ctx, preds: torch.Tensor, targets: torch.Tensor):\n",
    "            with torch.enable_grad():\n",
    "                # necessary to flatten and unbind preds FIRST and then re-stack so they are part of the graph\n",
    "                preds_flat = preds.view(preds.size(0), -1)\n",
    "                samples = preds_flat.unbind(0)\n",
    "                value = loss_fn(torch.stack(samples).view_as(preds), targets)\n",
    "\n",
    "                # caluclate gradient and hessian\n",
    "                per_sample_H = []\n",
    "                per_sample_g = []\n",
    "                for sample in samples:\n",
    "                    g = torch.autograd.grad(value, sample, create_graph=True,)[0]\n",
    "                    H: torch.Tensor = jacobian([g], [sample])[0]\n",
    "                    per_sample_g.append(g)\n",
    "                    per_sample_H.append(H)\n",
    "\n",
    "            # stack\n",
    "            H = torch.stack(per_sample_H)\n",
    "            g = torch.stack(per_sample_g)\n",
    "\n",
    "            # apply regularization\n",
    "            if tik_l != 0:\n",
    "                I = torch.eye(H.size(-1), device=per_sample_H[0].device, dtype=per_sample_H[0].dtype).mul_(tik_l).unsqueeze(0)\n",
    "                H += I\n",
    "\n",
    "            # newton step\n",
    "            newton_step, success = torch.linalg.solve_ex(H, g)\n",
    "            ctx.save_for_backward(newton_step.view_as(preds))\n",
    "\n",
    "            return value\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, *grad_outputs):\n",
    "            newton_step = ctx.saved_tensors[0] # inputs to loss\n",
    "            return newton_step, None\n",
    "\n",
    "    return BatchedNewtonLoss.apply\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from monai.losses import DiceFocalLoss\n",
    "    dice = DiceFocalLoss(softmax=True)\n",
    "    # dice = torch.nn.MSELoss()\n",
    "\n",
    "    input = torch.randn(32,100, device='cuda')\n",
    "    target = (torch.rand(32,100, device='cuda') > 0.5).float()\n",
    "\n",
    "    x = input.clone().requires_grad_(True)\n",
    "    opt = torch.optim.SGD([x], 1)\n",
    "\n",
    "    print('normal dice')\n",
    "    for i in range(100):\n",
    "        loss = dice(x, target)\n",
    "        mse = (x-target).pow(2).mean()\n",
    "        print(f'{i}, {loss = }, {mse = }')\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "\n",
    "    newton_dice = make_batched_newton_loss(DiceFocalLoss(softmax=True), tik_l=1e-2)\n",
    "\n",
    "    x = input.clone().requires_grad_(True)\n",
    "    opt = torch.optim.SGD([x], 1)\n",
    "\n",
    "    # this is slow on dice because it calculates 32 100x100 hessians\n",
    "    # its for other losses but I only have dice installed\n",
    "    print('newton dice')\n",
    "    for i in range(100):\n",
    "        loss = newton_dice(x, target)\n",
    "        mse = (x-target).pow(2).mean()\n",
    "        print(f'{i}, {loss = }, {mse = }')\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
