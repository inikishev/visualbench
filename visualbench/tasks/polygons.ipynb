{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class DifferentiablePolygonRenderer(nn.Module):\n",
    "    def __init__(self, target_image, num_polygons=50, vertices_per_polygon=3, softness=1.0):\n",
    "        \"\"\"\n",
    "        target_image: a torch.Tensor of shape (3,H,W) with pixel values in [0,1]\n",
    "        num_polygons: number of polygons in the approximation\n",
    "        vertices_per_polygon: how many vertices per polygon\n",
    "        canvas_size: tuple, (H,W) dimensions of rendered image\n",
    "        softness: controls the blur of the edge (larger gives softer edges)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.target_image = target_image # should be float32 tensor (3, H, W)\n",
    "        self.num_polygons = num_polygons\n",
    "        self.vertices_per_polygon = vertices_per_polygon\n",
    "        self.canvas_height, self.canvas_width = target_image.shape[1:]\n",
    "        self.softness = softness\n",
    "        self.frames = [] # to store uint8 frame images\n",
    "\n",
    "        # Initialize polygon vertices: (num_polygons, vertices_per_polygon, 2)\n",
    "        # Coordinates in normalized space [0,1] (later multiplied by canvas size)\n",
    "        self.vertices = nn.Parameter(torch.rand(num_polygons, vertices_per_polygon, 2))\n",
    "        # Colors for each polygon: (num_polygons, 3), each channel in [0,1]\n",
    "        self.colors = nn.Parameter(torch.rand(num_polygons, 3))\n",
    "        # Alpha (opacity) for each polygon: (num_polygons,)\n",
    "        self.alpha = nn.Parameter(torch.rand(num_polygons))  # we'll use it for blending\n",
    "\n",
    "    def forward(self):\n",
    "        # Render the current polygons into an image\n",
    "        rendered = self.render_polygons()\n",
    "        # Compute loss (MSE) between rendered image and target image\n",
    "        loss = F.mse_loss(rendered, self.target_image)\n",
    "        # Convert rendered image to uint8 (0-255) and store in frames for visualization\n",
    "        with torch.no_grad():\n",
    "            # Clamp, and bring to CPU numpy format (3,H,W) with uint8 values\n",
    "            img_uint8 = (rendered.clamp(0,1)*255).byte().cpu().numpy()\n",
    "            # Transpose to H,W,3 if needed\n",
    "            img_uint8 = np.transpose(img_uint8, (1,2,0))\n",
    "            self.frames.append(img_uint8)\n",
    "        return loss\n",
    "\n",
    "    def render_polygons(self):\n",
    "        \"\"\"\n",
    "        Render all polygons onto a canvas using a differentiable soft rasterizer.\n",
    "        This implementation uses a soft mask for each polygon and blends over a white background.\n",
    "        \"\"\"\n",
    "        device = self.vertices.device\n",
    "\n",
    "        # Create a canvas grid\n",
    "        y = torch.linspace(0, 1, self.canvas_height, device=device).view(-1, 1).expand(self.canvas_height, self.canvas_width)\n",
    "        x = torch.linspace(0, 1, self.canvas_width, device=device).view(1, -1).expand(self.canvas_height, self.canvas_width)\n",
    "        grid = torch.stack([x, y], dim=-1)  # shape (H, W, 2)\n",
    "\n",
    "        # Prepare canvas for RGBA accumulation: start with white background.\n",
    "        canvas = torch.ones(3, self.canvas_height, self.canvas_width, device=device)\n",
    "\n",
    "        # For each polygon, compute soft mask and blend onto canvas\n",
    "        # We can vectorize the computation over the polygons.\n",
    "\n",
    "        # First, transform vertices to image coordinates\n",
    "        poly_vertices = self.vertices.clone()  # shape: (num_polygons, vertices_per_polygon, 2)\n",
    "        # They are normalized coordinates [0, 1]. No conversion needed since grid runs 0-1.\n",
    "\n",
    "        # Compute soft mask for each polygon: \n",
    "        # We use the idea of inside-outside function: for each edge of the polygon, compute the distance of each grid pixel to the edge.\n",
    "        # Then combine these distances with a sigmoid to produce a soft mask.\n",
    "        # We assume the polygon is convex for simplicity.\n",
    "        num_poly = self.num_polygons\n",
    "        mask = torch.ones(num_poly, self.canvas_height, self.canvas_width, device=device)\n",
    "\n",
    "        # vectorizing over vertices/edges\n",
    "        for j in range(self.vertices_per_polygon):\n",
    "            # current vertex index and next vertex index (with wrap-around)\n",
    "            v0 = poly_vertices[:, j, :]  # (num_poly, 2)\n",
    "            v1 = poly_vertices[:, (j+1) % self.vertices_per_polygon, :]  # (num_poly, 2)\n",
    "            # edge vector from v0 to v1\n",
    "            edge = v1 - v0  # (num_poly, 2)\n",
    "            # vector from v0 to each grid point: grid shape (H,W,2) -> unsqueeze polygon dim: (num_poly, H, W, 2)\n",
    "            vec = grid.unsqueeze(0) - v0.unsqueeze(1).unsqueeze(2)  # (num_poly, H, W, 2)\n",
    "            # Compute perp dot product to determine which side of the line the pixel is on.\n",
    "            # perp = (edge_y, -edge_x) for each edge\n",
    "            perp = torch.stack([edge[:,1], -edge[:,0]], dim=1)  # (num_poly, 2)\n",
    "            # Dot product for each polygon and each pixel:\n",
    "            dot = (vec * perp.unsqueeze(1).unsqueeze(2)).sum(dim=-1)  # (num_poly, H, W)\n",
    "            # Soft mask: for pixels inside, dot should be >= 0; use sigmoid for differentiability\n",
    "            edge_mask = torch.sigmoid(dot * self.softness)\n",
    "            # Combine: pixel is inside polygon if it is inside all edges\n",
    "            mask = mask * edge_mask  # (num_poly, H, W)\n",
    "\n",
    "        # Now, blend each polygon on canvas.\n",
    "        # We assume polygons are independent and apply alpha compositing.\n",
    "        # For each polygon, its contribution is: color * alpha * mask\n",
    "        # And the remaining canvas is: canvas*(1 - alpha*mask)\n",
    "        for i in range(num_poly):\n",
    "            p_mask = mask[i]  # shape (H, W)\n",
    "            a = torch.sigmoid(self.alpha[i])  # ensure in (0,1)\n",
    "            c = self.colors[i].view(3, 1, 1)  # shape (3,1,1)\n",
    "            # Alpha blending: new_pixel = p_mask*a*c + (1-p_mask*a)*old_pixel\n",
    "            canvas = p_mask * a * c + (1 - p_mask * a) * canvas\n",
    "\n",
    "        return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Loss: 1.5427018404006958\n",
      "Iteration 11, Loss: 0.35043835639953613\n",
      "Iteration 21, Loss: 0.28057435154914856\n",
      "Iteration 31, Loss: 0.21504658460617065\n",
      "Iteration 41, Loss: 0.20676743984222412\n",
      "Iteration 51, Loss: 0.19344347715377808\n",
      "Iteration 61, Loss: 0.18707914650440216\n",
      "Iteration 71, Loss: 0.18119540810585022\n",
      "Iteration 81, Loss: 0.17480488121509552\n",
      "Iteration 91, Loss: 0.1724458485841751\n",
      "Iteration 101, Loss: 0.1666036695241928\n",
      "Iteration 111, Loss: 0.16317059099674225\n",
      "Iteration 121, Loss: 0.16104786098003387\n",
      "Iteration 131, Loss: 0.17182639241218567\n",
      "Iteration 141, Loss: 0.15784022212028503\n",
      "Iteration 151, Loss: 0.14826609194278717\n",
      "Iteration 161, Loss: 0.15001191198825836\n",
      "Iteration 171, Loss: 0.16519232094287872\n",
      "Iteration 181, Loss: 0.14698506891727448\n",
      "Iteration 191, Loss: 0.14287249743938446\n",
      "Iteration 201, Loss: 0.13931120932102203\n",
      "Iteration 211, Loss: 0.13787956535816193\n",
      "Iteration 221, Loss: 0.13854244351387024\n",
      "Iteration 231, Loss: 0.13744333386421204\n",
      "Iteration 241, Loss: 0.1347547173500061\n",
      "Iteration 251, Loss: 0.13934659957885742\n",
      "Iteration 261, Loss: 0.1329018771648407\n",
      "Iteration 271, Loss: 0.137599378824234\n",
      "Iteration 281, Loss: 0.13029085099697113\n",
      "Iteration 291, Loss: 0.13011720776557922\n"
     ]
    }
   ],
   "source": [
    "from visualbench.utils import to_float_hw3_tensor\n",
    "from myai.transforms import znormalize, normalize\n",
    "\n",
    "target = znormalize(to_float_hw3_tensor(\"/var/mnt/ssd/Файлы/Изображения/Сохраненное/sanic.jpg\").moveaxis(-1, 0)[:,::3,::3])\n",
    "\n",
    "# Instantiate model\n",
    "model = DifferentiablePolygonRenderer(target, num_polygons=50, vertices_per_polygon=3, softness=50.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# For demonstration purposes, run a few iterations\n",
    "num_iterations = 300\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iteration {i+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# After training, you can visualize the final rendered image or any intermediate frames.\n",
    "# For example, to display the last frame:\n",
    "try:\n",
    "    from PIL import Image\n",
    "    final_frame = model.frames[-1]\n",
    "    im = Image.fromarray(final_frame)\n",
    "    im.show()\n",
    "except ImportError:\n",
    "    print(\"PIL is not installed; cannot display final frame.\")\n",
    "\n",
    "# Optionally, save the frames as an animation using your preferred tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myai.video import render_frames\n",
    "render_frames('poly', model.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PolygonOptimizer(nn.Module):\n",
    "    def __init__(self, target_image, num_polygons, num_vertices, tau=0.1, beta=10.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('target_image', target_image)\n",
    "        self.num_polygons = num_polygons\n",
    "        self.num_vertices = num_vertices\n",
    "        self.tau = tau\n",
    "        self.beta = beta\n",
    "        \n",
    "        # Assuming target_image is (3, H, W)\n",
    "        _, self.H, self.W = target_image.shape\n",
    "        \n",
    "        # Initialize vertices parameters in logit space (will be passed through sigmoid)\n",
    "        self.vertices_logit = nn.Parameter(torch.randn(num_polygons, num_vertices, 2))\n",
    "        \n",
    "        # Initialize color parameters in logit space (will be passed through sigmoid)\n",
    "        self.colors_logit = nn.Parameter(torch.randn(num_polygons, 4))\n",
    "        \n",
    "        self.frames = []\n",
    "    \n",
    "    def forward(self):\n",
    "        # Render the current image\n",
    "        current_image = self.render_polygons()\n",
    "        \n",
    "        # Compute loss against target image\n",
    "        loss = F.mse_loss(current_image, self.target_image)\n",
    "        \n",
    "        # Convert to uint8 and append to frames (detach and no grad)\n",
    "        with torch.no_grad():\n",
    "            current_image_uint8 = (current_image.clamp(0.0, 1.0) * 255).byte()\n",
    "            self.frames.append(current_image_uint8.cpu())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def render_polygons(self):\n",
    "        # Get vertices in [0, 1] with sigmoid\n",
    "        vertices = torch.sigmoid(self.vertices_logit)  # (N, V, 2)\n",
    "        N, V, _ = vertices.shape\n",
    "        \n",
    "        # Create pixel grid in [0, 1]\n",
    "        y_coords = torch.linspace(0, 1, self.H, device=vertices.device)\n",
    "        x_coords = torch.linspace(0, 1, self.W, device=vertices.device)\n",
    "        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "        pixels = torch.stack([grid_x, grid_y], dim=-1)  # (H, W, 2)\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        pixels = pixels.unsqueeze(2).unsqueeze(2)  # (H, W, 1, 1, 2)\n",
    "        vertices = vertices.unsqueeze(0).unsqueeze(0)  # (1, 1, N, V, 2)\n",
    "        \n",
    "        # Compute edges (v1, v2)\n",
    "        v1 = vertices\n",
    "        v2 = torch.roll(vertices, shifts=-1, dims=3)\n",
    "        edge_vec = v2 - v1  # (1, 1, N, V, 2)\n",
    "        \n",
    "        # Compute edge lengths\n",
    "        edge_length = torch.norm(edge_vec, dim=-1, keepdim=True) + 1e-8  # (1, 1, N, V, 1)\n",
    "        \n",
    "        # Compute cross product for each edge and pixel\n",
    "        dx = pixels[..., 0] - v1[..., 0]  # (H, W, N, V)\n",
    "        dy = pixels[..., 1] - v1[..., 1]\n",
    "        cross = dx * edge_vec[..., 1] - dy * edge_vec[..., 0]  # (H, W, N, V)\n",
    "        signed_distance = cross / edge_length.squeeze(-1)  # (H, W, N, V)\n",
    "        \n",
    "        # Compute smooth min distance per polygon (tau is temperature)\n",
    "        smooth_min_dist = -self.tau * torch.logsumexp(-signed_distance / self.tau, dim=-1)  # (H, W, N)\n",
    "        \n",
    "        # Compute mask using sigmoid (beta controls sharpness)\n",
    "        mask = torch.sigmoid(smooth_min_dist * self.beta)  # (H, W, N)\n",
    "        \n",
    "        # Get colors (RGBA) and apply sigmoid\n",
    "        colors = torch.sigmoid(self.colors_logit)  # (N, 4)\n",
    "        rgb = colors[:, :3]  # (N, 3)\n",
    "        a = colors[:, 3]  # (N,)\n",
    "        \n",
    "        # Compute alpha (mask * a) and premultiplied RGB\n",
    "        alpha = mask * a.view(1, 1, N)  # (H, W, N)\n",
    "        premultiplied_rgb = rgb.view(1, 1, N, 3) * alpha.unsqueeze(-1)  # (H, W, N, 3)\n",
    "        \n",
    "        # Compute transmittance for compositing\n",
    "        one_minus_alpha = 1 - alpha  # (H, W, N)\n",
    "        transmittance = torch.cumprod(one_minus_alpha, dim=2)  # (H, W, N)\n",
    "        transmittance = torch.roll(transmittance, shifts=1, dims=2)\n",
    "        transmittance[:, :, 0] = 1.0  # First polygon has full transmittance\n",
    "        \n",
    "        # Compute final image\n",
    "        contribution = premultiplied_rgb * transmittance.unsqueeze(-1)  # (H, W, N, 3)\n",
    "        final_image = torch.sum(contribution, dim=2)  # (H, W, 3)\n",
    "        \n",
    "        # Permute to (3, H, W) and clamp\n",
    "        final_image = final_image.permute(2, 0, 1).clamp(0.0, 1.0)\n",
    "        \n",
    "        return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Loss: 0.9926592111587524\n",
      "Iteration 11, Loss: 0.868086576461792\n",
      "Iteration 21, Loss: 0.7758312225341797\n",
      "Iteration 31, Loss: 0.733272135257721\n",
      "Iteration 41, Loss: 0.7123379707336426\n",
      "Iteration 51, Loss: 0.6996484994888306\n",
      "Iteration 61, Loss: 0.6917396187782288\n",
      "Iteration 71, Loss: 0.684929609298706\n",
      "Iteration 81, Loss: 0.6799998879432678\n",
      "Iteration 91, Loss: 0.6778824925422668\n",
      "Iteration 101, Loss: 0.6761957406997681\n",
      "Iteration 111, Loss: 0.6750072836875916\n",
      "Iteration 121, Loss: 0.6742349863052368\n",
      "Iteration 131, Loss: 0.6737663149833679\n",
      "Iteration 141, Loss: 0.673454225063324\n",
      "Iteration 151, Loss: 0.6731721758842468\n",
      "Iteration 161, Loss: 0.6729599833488464\n",
      "Iteration 171, Loss: 0.6727607846260071\n",
      "Iteration 181, Loss: 0.6725674271583557\n",
      "Iteration 191, Loss: 0.6723613739013672\n",
      "Iteration 201, Loss: 0.6720983982086182\n",
      "Iteration 211, Loss: 0.6717106699943542\n",
      "Iteration 221, Loss: 0.671209990978241\n",
      "Iteration 231, Loss: 0.6710312962532043\n",
      "Iteration 241, Loss: 0.6709325909614563\n",
      "Iteration 251, Loss: 0.6708356738090515\n",
      "Iteration 261, Loss: 0.6707432270050049\n",
      "Iteration 271, Loss: 0.6706463694572449\n",
      "Iteration 281, Loss: 0.670542299747467\n",
      "Iteration 291, Loss: 0.6704314947128296\n"
     ]
    }
   ],
   "source": [
    "from visualbench.utils import to_float_hw3_tensor\n",
    "from myai.transforms import znormalize, normalize\n",
    "\n",
    "target = znormalize(to_float_hw3_tensor(\"/var/mnt/ssd/Файлы/Изображения/Сохраненное/sanic.jpg\").moveaxis(-1, 0)[:,::2,::2])\n",
    "\n",
    "# Instantiate model\n",
    "model = PolygonOptimizer(target, num_polygons=50, num_vertices=3, beta=200)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# For demonstration purposes, run a few iterations\n",
    "num_iterations = 300\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iteration {i+1}, Loss: {loss.item()}\")\n",
    "\n",
    "from myai.video import render_frames\n",
    "render_frames('poly2', model.frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
